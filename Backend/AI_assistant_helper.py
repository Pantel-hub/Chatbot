import json
import os
import time
import logging
import anyio
from typing import Dict, Any, Optional, List
from tempfile import NamedTemporaryFile
from datetime import datetime, timezone

from openai import OpenAI, AsyncOpenAI

from database_connection import get_db


async_openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
logger = logging.getLogger(__name__)

# âœ… Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î±Ï…Ï„ÏÎ½ Ï„Ï‰Î½ 3 Î³ÏÎ±Î¼Î¼ÏÎ½
print("=" * 50)
print(f"ğŸ”‘ OPENAI_API_KEY exists: {bool(os.getenv('OPENAI_API_KEY'))}")
print(f"ğŸ”‘ openai_client type: {type(openai_client)}")
print(f"ğŸ”‘ Has .beta attribute: {hasattr(openai_client, 'beta')}")
if hasattr(openai_client, "beta"):
    print(f"ğŸ”‘ Has .beta.vector_stores: {hasattr(openai_client.beta, 'vector_stores')}")
print("=" * 50)


###Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î· Î•Î¾Î±Î¯ÏÎµÏƒÎ· Î³Î¹Î± Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ files Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ###
class KnowledgeProcessingError(Exception):
    """Custom exception for knowledge processing failures."""

    pass


# Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Ï‰ ÏƒÏ„Î·Î½ Î²Î¬ÏƒÎ· vector,files ids Î¼Îµ Ï„Î± files ids Î½Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¿Î½Ï„Î±Î¹ ÏƒÎµ Î¼Î¿ÏÏ†Î® json
async def create_assistant_config(
    conn,
    chatbot_id: int,
    api_key: str,
    assistant_id: str,
    vector_store_id: str,
    file_ids: dict = None,
) -> int:

    async with conn.cursor() as cursor:
        await cursor.execute(
            """
            INSERT INTO assistant_configs 
            (chatbot_id, api_key, assistant_id, vector_store_id, openai_file_ids)
            VALUES (%s, %s, %s, %s, %s)
        """,
            (
                chatbot_id,
                api_key,
                assistant_id,
                vector_store_id,
                json.dumps(file_ids or {}),
            ),
        )

        return cursor.lastrowid


###Blocking ###


def process_knowledge_blocking(
    company_name: str,
    website_data: Optional[str],
    # Î¤Î± files Î­ÏÏ‡Î¿Î½Ï„Î±Î¹ Ï‰Ï‚ List[tuple] Î±Ï€ÏŒ Ï„Î¿ cms_routes: [(filename, temp_path), ...]
    local_file_paths: List[Dict[str, str]],
) -> Dict[str, Any]:
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Vector Store, Î±Î½ÎµÎ²Î¬Î¶ÎµÎ¹ website data (Î¼Î­ÏƒÏ‰ temp file) ÎºÎ±Î¹ files.
    Î•Î¯Î½Î±Î¹ BLOCKING - Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ±Î»ÎµÎ¯Ï„Î±Î¹ Î¼Îµ to_thread.run_sync.
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ vector_store_id ÎºÎ±Î¹ openai_file_ids.
    """
    # Î¼Î¹Î± Î»Î¯ÏƒÏ„Î± Î±Ï€ÏŒ Î»ÎµÎ¾Î¹ÎºÎ¬ Î¿Ï€Î¿Ï… Î¸Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¿Î½Ï„Î±Î¹ Î¿Î»Î± Ï„Î± Î±ÏÏ‡ÎµÎ¹Î± Ï€Î¿Ï… Î¸Î± Î±Î½ÎµÎ²Î¿Ï…Î½ ÏƒÏ„Î¿ vector store
    all_file_paths = []

    # Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¹Î·ÏƒÎ· Î¼ÎµÏ„Î±Î²Î»Î·Ï„Î·Ï‚ Î³Î¹Î± Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ website_data.txt
    temp_website_file_path = None

    try:
        # ------------------- 1. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î‘ÏÏ‡ÎµÎ¯Î¿Ï… (Website Data) -------------------
        if website_data:
            logger.info("Starting temp file creation for website data.")
            # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ NamedTemporaryFile
            with NamedTemporaryFile(
                mode="w+t",
                delete=False,  # Î¤Î¿ Î±Ï†Î®Î½Î¿Ï…Î¼Îµ Î±Î½Î¿Î¹Ï‡Ï„ÏŒ/Ï€ÏÎ¿ÏƒÎ²Î¬ÏƒÎ¹Î¼Î¿ Î¼Î­Ï‡ÏÎ¹ Ï„Î¿ finally block
                suffix=".txt",
                encoding="utf-8",
            ) as tmp:
                tmp.write(website_data)  # Î²Î¬Î¶Ï‰ Ï„Î± website_data ÏƒÎµ Î­Î½Î± Î±ÏÏ‡ÎµÎ¯Î¿ txt

            tmp.close()

            # Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ Ï„Î·Î½ Ï€Î»Î®ÏÎ· Î´Î¹Î±Î´ÏÎ¿Î¼Î® string Ï„Î¿Ï… Ï€ÏÎ¿ÏƒÏ‰ÏÎ¯Î½Î¿Ï… Î±ÏÏ‡ÎµÎ¹Î¿Ï… ÎºÎ±Î¹ Ï„Î·Î½ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…ÎµÎ¹ ÏƒÏ„Î·Î½
            # Î¼ÎµÏ„Î±Î²Î»Î·Ï„Î· temp_website_file_path
            temp_website_file_path = tmp.name

            # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î· Î»Î¯ÏƒÏ„Î± upload
            all_file_paths.append(
                {
                    "path": temp_website_file_path,
                    "type": "website",
                    "filename_key": "website_data",
                }
            )
            logger.info(f"Created temp website file: {temp_website_file_path}")

        # ------------------- 2. Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Local Files (Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Ï‡ÏÎ®ÏƒÏ„Î·) -------------------
        # Î¤Î± local_file_paths Î­ÏÏ‡Î¿Î½Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ cms_routes (Î±ÏÏ‡ÎµÎ¯Î± Ï‡ÏÎ®ÏƒÏ„Î·)
        all_file_paths.extend(local_file_paths)

        # ------------------- 3. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Vector Store -------------------

        if not all_file_paths:
            logger.warning("No knowledge data provided for Vector Store.")
            # Î‘ÎºÏŒÎ¼Î· ÎºÎ¹ Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÏ‡ÎµÎ¯Î±, Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Ï„Î¿ Vector Store
            # Î³Î¹Î± Î¼ÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ·.
            vector_store = openai_client.beta.vector_stores.create(
                name=f"{company_name} Knowledge Store"
            )
            return {"vector_store_id": vector_store.id, "openai_file_ids": {}}

        # Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿ vector store
        vector_store = openai_client.beta.vector_stores.create(
            name=f"{company_name} Knowledge Store"
        )
        logger.info(f"Vector Store created: {vector_store.id}")

        # ------------------- 4. Upload Files ÏƒÏ„Î¿ Vector Store -------------------

        openai_file_ids_map = {}  # Î»ÎµÎ¾Î¹ÎºÎ¿ Î¼Îµ file_name:openai_file_id
        upload_file_ids = (
            []
        )  # Î»Î¯ÏƒÏ„Î± Î¼Îµ Ï„Î± Î±Î½Î±Î³Î½Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ ids Ï„Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Ï„Î¿ Ï‡ÏÎµÎ¹Î±Î¶ÎµÏ„Î±Î¹ Î· openai Î³Î¹Î± Ï„Î¿ indexing

        # 4.1 Upload files to OpenAI
        failed_uploads = []
        for file_info in all_file_paths:
            file_path = file_info["path"]
            filename_key = file_info["filename_key"]  # ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…

            # Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ context manager Î³Î¹Î± Î±ÏƒÏ†Î±Î»Î® ÎºÎ»Î®ÏƒÎ· Ï„Î¿Ï… open()
            try:
                with open(file_path, "rb") as f:
                    uploaded_file = openai_client.files.create(
                        file=f, purpose="assistants"
                    )

                openai_file_ids_map[filename_key] = (
                    uploaded_file.id
                )  # Î±Ï†Î¿Ï… Î­Ï‡ÎµÎ¹ Î±Î½ÎµÎ²ÎµÎ¹ ÎºÎ±Î¹ Î­Ï‡ÎµÎ¹ Î±Ï€Î¿ÎºÏ„Î®ÏƒÎµÎ¹ id

                upload_file_ids.append(uploaded_file.id)
                logger.info(
                    f"File uploaded to OpenAI: {filename_key} -> {uploaded_file.id}"
                )

            except Exception as e:
                logger.warning(f"âš ï¸ Failed to upload {filename_key}: {e}")
                failed_uploads.append({"filename": filename_key, "error": str(e)})
                continue

        if failed_uploads:
            logger.warning(f"âš ï¸ {len(failed_uploads)} file(s) failed to upload")
        if upload_file_ids:
            logger.info(f"âœ… {len(upload_file_ids)} file(s) uploaded successfully")

        if not upload_file_ids:
            logger.warning(
                "âš ï¸ No files were successfully uploaded to add to Vector Store"
            )
            return {
                "vector_store_id": vector_store.id,
                "openai_file_ids": {},
                "failed_uploads": failed_uploads,
            }

        # 4.2 Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Ï‰Î½ uploaded files ÏƒÏ„Î¿ Vector Store ÎºÎ±Î¹ indexing
        openai_client.beta.vector_stores.file_batches.create_and_poll(
            vector_store_id=vector_store.id, file_ids=upload_file_ids
        )
        logger.info(f"All files added and processed by Vector Store: {vector_store.id}")

        # ------------------- 5. Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ -------------------
        # Ï†Ï„Î¯Î±Ï‡Î½ÎµÎ¹ Î­Î½Î± Î»ÎµÎ¾Î¹ÎºÏŒ (Î¼ÎµÏ„Î±Ï„ÏÎ¿Ï€Î· ÏƒÎµ json) ÏŒÏ€Î¿Ï… Î¸Î± Î­Ï‡ÎµÎ¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î±Î½Î­Î²Î·ÎºÎ±Î½
        # Î³Î¹Î± Î½Î± Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏƒÏ‰ ÏƒÏ„Î·Î½ Î²Î¬ÏƒÎ·
        structured_file_ids = {}
        for filename_key, file_id in openai_file_ids_map.items():
            if filename_key == "website_data":
                structured_file_ids[filename_key] = {
                    "file_id": file_id,
                    "filename": "website_data.txt",
                    "type": "website",
                }
            elif filename_key == "faq_data":
                structured_file_ids[filename_key] = {
                    "file_id": file_id,
                    "filename": "faq_data.txt",
                    "type": "faq",
                    "uploaded_at": datetime.now(timezone.utc).isoformat(),
                }
            else:
                structured_file_ids[filename_key] = {
                    "file_id": file_id,
                    "filename": filename_key,
                    "type": "user_file",
                    "uploaded_at": datetime.now(timezone.utc).isoformat(),
                }

        return {
            "vector_store_id": vector_store.id,
            "openai_file_ids": structured_file_ids,
            "failed_uploads": failed_uploads,
        }

    except Exception as e:
        logger.error(f"âŒ OpenAI API or File Error: {e}")
        raise KnowledgeProcessingError(
            f"Failed to process knowledge data with OpenAI: {e}"
        )

    finally:
        # ------------------- 6. Î¤ÎµÎ»Î¹ÎºÎ® Î”Î¹Î±Î³ÏÎ±Ï†Î® Î ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¿Ï Î‘ÏÏ‡ÎµÎ¯Î¿Ï… Website -------------------
        if temp_website_file_path and os.path.exists(temp_website_file_path):
            try:
                os.unlink(temp_website_file_path)
                logger.info(
                    f"âœ… Deleted temporary website file: {temp_website_file_path}"
                )
            except Exception as e:
                logger.warning(
                    f"âš ï¸ Failed to delete temporary file {temp_website_file_path}: {e}"
                )


### ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï…Ï€Î¬ÏÏ‡Î¿Î½Ï„Î¿Ï‚ vector store ###
def update_vector_store_blocking(
    vector_store_id: str,
    existing_file_ids: dict,
    website_data: Optional[str],
    local_file_paths: List[Dict[str, str]],
    update_website: bool = False,
    update_faq: bool = False,
    faq_text: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Î•Î½Î·Î¼ÎµÏÏÎ½ÎµÎ¹ Ï…Ï€Î¬ÏÏ‡Î¿Î½ Vector Store Î¼Îµ Î½Î­Î± files/website data.
    Î•Î¯Î½Î±Î¹ BLOCKING - Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ±Î»ÎµÎ¯Ï„Î±Î¹ Î¼Îµ to_thread.run_sync.

    """
    temp_website_file_path = None
    temp_faq_file_path = None
    existing_file_ids = existing_file_ids or {}
    updated_file_ids = existing_file_ids.copy()  # Î±Î½Ï„Î¹Î³ÏÎ±Ï†Î¿ Ï„Î¿Ï… existing files ids

    try:
        # ------------------- 1. Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Website Data -------------------
        if update_website and website_data:
            logger.info("ğŸ”„ Updating website data...")

            # Î”Î¹Î±Î³ÏÎ±Ï†Î® Ï€Î±Î»Î¹Î¿Ï website file (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
            if "website_data" in existing_file_ids:
                old_file_id = existing_file_ids["website_data"]["file_id"]
                try:
                    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Î±Ï€ÏŒ Vector Store
                    openai_client.beta.vector_stores.files.delete(
                        vector_store_id=vector_store_id, file_id=old_file_id
                    )
                    logger.info(
                        f"ğŸ—‘ï¸ Deleted old website file from Vector Store: {old_file_id}"
                    )

                    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Î±Ï€ÏŒ OpenAI
                    openai_client.files.delete(old_file_id)
                    logger.info(
                        f"ğŸ—‘ï¸ Deleted old website file from OpenAI: {old_file_id}"
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to delete old website file: {e}")

            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Î¿Ï… temp file
            with NamedTemporaryFile(
                mode="w+t", delete=False, suffix=".txt", encoding="utf-8"
            ) as tmp:
                tmp.write(website_data)

            tmp.close()
            temp_website_file_path = tmp.name

            # Upload Î½Î­Î¿Ï… file
            with open(temp_website_file_path, "rb") as f:
                new_website_file = openai_client.files.create(
                    file=f, purpose="assistants"
                )

            # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ Vector Store
            openai_client.beta.vector_stores.files.create(
                vector_store_id=vector_store_id, file_id=new_website_file.id
            )

            # Update Ï„Î¿ dictionary
            updated_file_ids["website_data"] = {
                "file_id": new_website_file.id,
                "filename": "website_data.txt",
                "type": "website",
            }

            logger.info(f"âœ… Website data updated: {new_website_file.id}")

        # ------------------- 2. Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· faq data -------------------
        if update_faq and faq_text:
            logger.info("ğŸ”„ Updating FAQ data...")

            if "faq_data" in existing_file_ids:
                old_faq_file_id = existing_file_ids["faq_data"]["file_id"]
                try:
                    # Î”Î¹Î±Î³ÏÎ±Ï†Î® Î±Ï€ÏŒ Vector Store
                    openai_client.beta.vector_stores.files.delete(
                        vector_store_id=vector_store_id, file_id=old_faq_file_id
                    )
                    logger.info(
                        f"ğŸ—‘ï¸ Deleted old FAQ file from Vector Store: {old_faq_file_id}"
                    )

                    openai_client.files.delete(old_faq_file_id)
                    logger.info(
                        f"ğŸ—‘ï¸ Deleted old FAQ file from OpenAI: {old_faq_file_id}"
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to delete old FAQ file: {e}")

            with NamedTemporaryFile(
                mode="w+t", delete=False, suffix=".txt", encoding="utf-8"
            ) as tmp_faq:
                tmp_faq.write(faq_text)
            tmp_faq.close()
            temp_faq_file_path = tmp_faq.name

            # Upload Î½Î­Î¿Ï… FAQ file
            with open(temp_faq_file_path, "rb") as f:
                new_faq_file = openai_client.files.create(file=f, purpose="assistants")

            # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ Vector Store
            openai_client.beta.vector_stores.files.create(
                vector_store_id=vector_store_id, file_id=new_faq_file.id
            )

            # Update Ï„Î¿ dictionary
            updated_file_ids["faq_data"] = {
                "file_id": new_faq_file.id,
                "filename": "faq_data.txt",
                "type": "faq",
                "uploaded_at": datetime.now(timezone.utc).isoformat(),
            }

            logger.info(f"âœ… FAQ data updated: {new_faq_file.id}")
        elif update_faq and not faq_text:
            logger.warning(
                "âš ï¸ update_faq=True Î±Î»Î»Î¬ Î´ÎµÎ½ Î´ÏŒÎ¸Î·ÎºÎµ faq_text â€” skip FAQ update."
            )

        # ------------------- 3. Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· User Files -------------------
        if local_file_paths:
            logger.info(f"ğŸ“¤ Uploading {len(local_file_paths)} new user files...")

            for file_info in local_file_paths:
                file_path = file_info["path"]
                filename_key = file_info["filename_key"]
                if filename_key in ("website_data", "faq_data"):
                    logger.info(
                        f"â­ï¸ Skipping {filename_key} â€” already handled separately."
                    )
                    continue

                # Upload file
                with open(file_path, "rb") as f:
                    uploaded_file = openai_client.files.create(
                        file=f, purpose="assistants"
                    )

                # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ Vector Store
                openai_client.beta.vector_stores.files.create(
                    vector_store_id=vector_store_id, file_id=uploaded_file.id
                )

                # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ dictionary
                updated_file_ids[filename_key] = {
                    "file_id": uploaded_file.id,
                    "filename": filename_key,
                    "type": "user_file",
                    "uploaded_at": datetime.now(timezone.utc).isoformat(),
                }

                logger.info(f"âœ… File uploaded: {filename_key} -> {uploaded_file.id}")

        # ------------------- 3. Î•Ï€Î¹ÏƒÏ„ÏÎ¿Ï†Î® -------------------
        logger.info(f"âœ… Vector Store updated successfully: {vector_store_id}")

        return {"vector_store_id": vector_store_id, "openai_file_ids": updated_file_ids}

    except Exception as e:
        logger.error(f"âŒ Vector Store update failed: {e}")
        raise KnowledgeProcessingError(f"Failed to update Vector Store: {e}")

    finally:
        # Cleanup temp website file
        if temp_website_file_path and os.path.exists(temp_website_file_path):
            try:
                os.unlink(temp_website_file_path)
                logger.info(f"ğŸ§¹ Deleted temp website file")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to delete temp file: {e}")

        if temp_faq_file_path and os.path.exists(temp_faq_file_path):
            try:
                os.unlink(temp_faq_file_path)
                logger.info("ğŸ§¹ Deleted temp FAQ file")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to delete temp FAQ file: {e}")


### Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î· Î½Î± Î´Î¹Î±Î³ÏÎ±ÏˆÎµÎ¹ Î±ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î­Ï‡ÎµÎ¹ Î±Î½ÎµÎ²Î¬ÏƒÎµÎ¹ ###
def delete_file_from_vector_store_blocking(vector_store_id: str, file_id: str) -> bool:
    """
    Args:
        vector_store_id: Î¤Î¿ Vector Store ID
        file_id: Î¤Î¿ OpenAI file ID Ï€ÏÎ¿Ï‚ Î´Î¹Î±Î³ÏÎ±Ï†Î®

    Returns:
        True Î±Î½ ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚, False Î±Î½ Î±Ï€Î¿Ï„Ï…Ï‡Î¯Î±
    """
    try:
        # 1. Î”Î¹Î±Î³ÏÎ±Ï†Î® Î±Ï€ÏŒ Vector Store
        openai_client.beta.vector_stores.files.delete(
            vector_store_id=vector_store_id, file_id=file_id
        )
        logger.info(f"ğŸ—‘ï¸ File removed from Vector Store: {file_id}")

        # 2. Î”Î¹Î±Î³ÏÎ±Ï†Î® Î±Ï€ÏŒ OpenAI
        openai_client.files.delete(file_id)
        logger.info(f"ğŸ—‘ï¸ File deleted from OpenAI: {file_id}")

        return True

    except Exception as e:
        logger.error(f"âŒ Failed to delete file {file_id}: {e}")
        return False


# ÏƒÎºÎ¿Ï€ÏŒÏ‚ Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¹ assistant ÎºÎ±Î¹ Î½Î± Ï„Î¿Î½ ÏƒÏ…Î½Î´Î­ÎµÎ¹ Î¼Îµ Ï„Î¿ vector store Ï„Î·Ï‚ ÎµÏ„Î±Î¹ÏÎ¯Î±Ï‚
async def create_assistant_async(
    company_name: str, api_key: str, system_prompt: str, vector_store_id: str
) -> str:
    try:
        assistant = await async_openai_client.beta.assistants.create(
            name=f"{company_name} - {api_key}",
            instructions=system_prompt,
            model="gpt-4o",
            tools=[{"type": "file_search"}],
            tool_resources={"file_search": {"vector_store_ids": [vector_store_id]}},
        )

        logger.info(f"âœ… Assistant created: {assistant.id}")
        return assistant.id

    except Exception as e:
        logger.error(f"âŒ Failed to create Assistant: {e}")
        raise KnowledgeProcessingError(f"Failed to create Assistant: {e}")


# Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÏƒÏ„Î¿ AI_assistant_helper.py


async def get_or_create_thread(thread_id: Optional[str] = None) -> str:
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î® ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î­Î½Î± thread ID.

    Args:
        thread_id: Î¥Ï€Î¬ÏÏ‡Î¿Î½ thread ID (optional)

    Returns:
        str: Thread ID

    """
    try:
        if thread_id:
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„Î¿ thread
            try:
                await async_openai_client.beta.threads.retrieve(thread_id)
                logger.info(f"âœ… Using existing thread: {thread_id}")
                return thread_id
            except Exception as e:
                # Thread Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ â†’ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Î¿Ï…
                logger.warning(f"âš ï¸ Thread {thread_id} not found, creating new one: {e}")

        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Î¿Ï… thread
        thread = await async_openai_client.beta.threads.create()
        logger.info(f"âœ… Created new thread: {thread.id}")
        return thread.id

    except Exception as e:
        logger.error(f"âŒ Failed to get/create thread: {e}")
        raise Exception(f"Thread management failed: {e}")


async def add_message_to_thread(
    thread_id: str, message: str, role: str = "user"
) -> str:
    """
    Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ Î¼Î®Î½Ï…Î¼Î± ÏƒÎµ Î­Î½Î± thread.

    Args:
        thread_id: Î¤Î¿ ID Ï„Î¿Ï… thread
        message: Î¤Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ Ï„Î¿Ï… Î¼Î·Î½ÏÎ¼Î±Ï„Î¿Ï‚
        role: "user" Î® "assistant"

    Returns:
        str: Message ID

    Raises:
        Exception: Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Î· Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î¼Î·Î½ÏÎ¼Î±Ï„Î¿Ï‚
    """
    try:
        # Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î­Î½Î± message object ÏƒÏ„Î¿ thread
        thread_message = await async_openai_client.beta.threads.messages.create(
            thread_id=thread_id, role=role, content=message
        )
        logger.info(
            f"âœ… Added {role} message to thread {thread_id}: {thread_message.id}"
        )
        return thread_message.id

    except Exception as e:
        logger.error(f"âŒ Failed to add message to thread {thread_id}: {e}")
        raise Exception(f"Failed to add message: {e}")


async def run_assistant_on_thread(thread_id: str, assistant_id: str):
    """
    Î¤ÏÎ­Ï‡ÎµÎ¹ Ï„Î¿Î½ assistant ÏƒÎµ Î­Î½Î± thread Î¼Îµ streaming.

    Args:
        thread_id: Î¤Î¿ ID Ï„Î¿Ï… thread
        assistant_id: Î¤Î¿ ID Ï„Î¿Ï… assistant

    Yields:
        str: Text chunks Î±Ï€ÏŒ Ï„Î·Î½ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Ï„Î¿Ï… assistant

    Raises:
        Exception: Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î¿Ï… assistant
    """
    try:
        logger.info(f"ğŸ¤– Running assistant {assistant_id} on thread {thread_id}")

        async with async_openai_client.beta.threads.runs.stream(
            thread_id=thread_id, 
            assistant_id=assistant_id, 
            temperature=0.2,
            top_p=0.9,
        ) as stream:
            async for event in stream:
                # Streaming events Î±Ï€ÏŒ Ï„Î¿ OpenAI
                # Î±Î½ ÎµÎ¹Î½Î±Î¹ ÎºÎ¿Î¼Î¼Î±Ï„Î¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚
                if event.event == "thread.message.delta":
                    if hasattr(event.data, "delta") and hasattr(
                        event.data.delta, "content"
                    ):
                        for content_block in event.data.delta.content:
                            if hasattr(content_block, "text") and hasattr(
                                content_block.text, "value"
                            ):
                                yield content_block.text.value

                elif event.event == "thread.run.failed":
                    logger.error(f"âŒ Assistant run failed: {event.data}")
                    raise Exception(f"Assistant run failed: {event.data.last_error}")

                elif event.event == "thread.run.completed":
                    logger.info(f"âœ… Assistant run completed for thread {thread_id}")

    except Exception as e:
        logger.error(f"âŒ Failed to run assistant on thread {thread_id}: {e}")
        raise Exception(f"Assistant execution failed: {e}")


### Î“Î¹Î± Ï„Î¿ widget ###
# Ï€Î±Î¯ÏÎ½ÎµÎ¹ Ï„Î¿ assistant_id Î±Ï€ÏŒ Ï„Î¿ api_key Ï„Î·Ï‚ ÎµÏ„Î±Î¹ÏÎ¯Î±Ï‚
async def get_assistant_id_by_api_key(api_key: str) -> Optional[str]:
    try:
        async with get_db() as conn:
            async with conn.cursor() as cursor:
                await cursor.execute(
                    "SELECT assistant_id FROM assistant_configs WHERE api_key = %s",
                    (api_key,),
                )
                row = await cursor.fetchone()

                if row:
                    logger.info(f"âœ… Found assistant_id for api_key:{api_key[:10]}")
                    return row["assistant_id"]

                logger.warning(f"âš ï¸ No assistant found for api_key: {api_key[:10]}...")
                return None

    except Exception as e:
        logger.error(f"âŒ Failed to get assistant_id for api_key: {e}")
        return None


### Î”Î¹Î±Î³ÏÎ±Ï†Î® Thread Î³Î¹Î± Test Sessions ###
async def delete_thread_async(thread_id: str) -> bool:
    """Î”Î¹Î±Î³ÏÎ¬Ï†ÎµÎ¹ Î­Î½Î± thread Î±Ï€ÏŒ Ï„Î¿ OpenAI API."""
    try:
        await async_openai_client.beta.threads.delete(thread_id)
        logger.info(f"ğŸ—‘ï¸ Successfully deleted thread: {thread_id}")
        return True

    except Exception as e:
        # Î‘Î½ Ï„Î¿ thread Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î® Î¬Î»Î»Î¿ error, Î´ÎµÎ½ ÎºÎ¬Î½Î¿Ï…Î¼Îµ crash
        logger.warning(f"âš ï¸ Failed to delete thread {thread_id}: {e}")
        return False
